batch_size = 128
seed = 0
embedding_tuning = False
min_freq = 0
word_dim = 300
hidden_dim = 512
dropout = 0.1
learning_rate = 1e-3
weight_decay = 1e-5
clip_grad = 1e1
layer = 4
warm_up_steps = 40000
gradual_unfreeze = True
layer_lr_decay = 0.95
ratio = 32
cut_frac = 0.2
is_output_lr_normal = True
mask_p = 1
